{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting started: Review of Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics is a big discipline concerned with the collection, analysis and interpretation of data. If you are taking this course, then you have already taken a Statistics course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a brief review of concepts needed in the context of Data Science and Machine Learning. For a complete review, please follow the sources provided at the end of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any concepts in this document that you are unfamiliar or *rusty* about, please review them as soon as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sample Space and Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Probability\n",
    "\n",
    "The concept of **probability** is used to assess uncertainty of a situation, which can broadly be defined in two ways:\n",
    "\n",
    "* *Frequency of Occurrence* (frequentist view): percentage of successes in a moderately large number of similar situations.\n",
    "* *Subjective Belief* (Bayesian view): use of personnal/group/cultural beliefs for given experiences of successful decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Experiment\n",
    "\n",
    "* An **experiment** is a procedure carried out to support, refute a *hypothesis*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* An **outcome** is the result of a single trial of an **experiment**. For example, when flipping a coin the possible outcomes are Heads (H) or Tails (T)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* An **event** is one or more outcomes of an **experiment**. For example, when flipping a coin 3 times observing the result HHH is an event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **relative frequency** of an event is the number of times that an event occurs divided by the number of times the experiment is conducted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Simulation Experiments\n",
    "\n",
    "In many practical situations, the analytical calculation of the probability of some event of interest is very difficult. If we have a physical or computer model that can generate outcomes of a given experiment in accordance with their *true probabilities*, we can use a **simulation experiment** to calculate with high accuracy the probability of any given event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A **computer simulation** is a computer program that models reality and allows us to conduct experiments that:\n",
    "* would *require a lot of time* to carry out in real life\n",
    "* would *require a lot of resources* to carry out in real life\n",
    "* would *not be possible to repeat* in real life (for instance, simulation of the next day's weather or stock market performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Generally we are not only interested in asking about the probabilities of **outcomes** but also the probabilities of **events**, which are combinations of outcomes.\n",
    "\n",
    "* An event is a **set**.\n",
    "\n",
    "* The **probability** of an event is a number between 0 and 1 that quantifies how likely that event is to occur. An event that cannot occur has probability 0, and an event that is sure to occur has probability 1. The probabilities of the outcomes sum to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* We say an experiment is **fair** if every outcome is equally likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sets and Set Operations\n",
    "\n",
    "* The **subset operator** $\\subset$ (reads \"A is a subset of B\") is defined for two sets $A$ and $B$ by: \n",
    "$$A\\subset B\\text{ if } x\\in A \\Rightarrow x \\in B$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **union** of $A$ and $B$ (reads \"A union B\" or \"A or B\") is a set defined by: \n",
    "$$A\\cup B =\\left\\{x | x\\in A\\text{ or }x\\in B\\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The **intersection** of $A$ and $B$ (reads \"A intersect B\" or \"A and B\") is a set defined by: \n",
    "$$A\\cap B = AB = \\left\\{x | x\\in A\\text{ and }x\\in B\\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **complement** of a set $A$ (reads \"A complement\") in a sample space $\\Omega$ is defined by: \n",
    "$$A^c = \\overline{A} = \\left\\{x | x\\in \\Omega\\text{ and }x\\notin A\\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The **Venn diagram** if a fundamental tools for understanding set operations as it shows all possible logical relations between a finite collection of sets.\n",
    "\n",
    "![VennDiagram](https://www.onlinemathlearning.com/image-files/set-operations-venn-diagrams.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Two sets $A$ and $B$ are said to be **mutually exclusive** or **disjoint** if and only if (iff) $A\\cap B = \\emptyset$. (This is a set relation!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **cardinality** of a set $S$, denoted $|S|$, is the number of elements in that set.\n",
    "\n",
    "    * A set $S$ is **finite** if $|S| = N < \\infty$\n",
    "    \n",
    "    * A set $S$ is **countably infinite** if $|S| = |\\mathcal{\\mathbb{Z}}|$, i.e., it can be put into one-to-one correspondence with the integers.\n",
    "    \n",
    "    * A set $S$ is **uncountably infinite** if $|S| > |\\mathcal{\\mathbb{Z}}|$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* If $a$ and $b$ ($b>a$) are in an **interval** $I$, then if $a \\leq x \\leq b$, $x\\in I$.\n",
    "\n",
    "    * A closed interval $[a,b]$ contains the endpoints of $a$ and $b$.\n",
    "    * An open interval $(a,b)$ does not contain the endpoints of $a$ and $b$.\n",
    "    * An interval can be half-open, such as $(a,b]$, which does not contain $a$, or $[a,b)$, which does not contain $b$.\n",
    "    * Intervals can also be either finite, infinite, or partially infinite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A **discrete set** is either finite or countably infinite.\n",
    "\n",
    "* A **continuous set** is not countable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Probabilistic Models\n",
    "\n",
    "The elements of a probabilistic model are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **sample space** $\\Omega$, which is the set of all possible outcomes of an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **event** $A$, which is a *subset* ($A\\subset \\Omega$) of the sample space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **probability law**, which assigns to a set $A$ of possible outcomes a non-negative probability number $P(A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Probability Axioms**\n",
    "\n",
    "1. **Non-negativity**: $P(A)\\geq 0$, for every event $A$.\n",
    "\n",
    "2. **Additivity**: If $A$ and $B$ are mutually exclusive (disjoint events), then the probability of their union satisfies\n",
    "$P(A\\cup B)=P(A) + P(B)$\n",
    "\n",
    "3. **Normalization**: The probability of the entire sample space $\\Omega$ is equal to 1, that is, $P(\\Omega)=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**(Some) Properties of Probability Laws**\n",
    "\n",
    "1. If $A\\subset B$, then $P(A)\\leq P(B)$\n",
    "2. $P(A^c) = 1 - P(A)$\n",
    "3. $P(A)\\leq 1$\n",
    "4. $P(\\emptyset)=0$\n",
    "5. $P(A\\cup B) = P(A) + P(B) - P(A\\cap B)$\n",
    "6. $P(A\\cup B) \\leq P(A) + P(B)$\n",
    "7. $P(A\\cup B\\cup C) = P(A) + P(A^c \\cap B) + P(A^c\\cap B^c \\cap C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sequential Models\n",
    "\n",
    "A **combined experiment** or **sequential experiment** is an experiment that consists of a sequence of sub-experiments. When ordered, the sub-experiments may depend on the outcome of previous sub-experiments. (For example, two rolls of a 4-sided die.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* It is often useful to describe the experiment and the associated sample space by means of a **tree-based sequential description**.\n",
    "\n",
    "![TreeSequentialModel](data:image/jpeg;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Combinatorics\n",
    "\n",
    "Combinatorics is the mathematics of **counting**. It can be used to find probabilities involving combinations of fair experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are two types of counting arguments that involve the selection of $k$ objects out of a collection of $n$ objects.\n",
    "\n",
    "* If the selection order matters, the selection is called a **permutation**\n",
    "* If the selection order does not matter, it is called a **combination**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The **cartesian product** of two sets $A$ and $B$ is denoted $A \\times B$ and is defined by \n",
    "\n",
    "$$ A \\times B = \\{ (a,b) | a \\in A \\mbox{ and } b \\in B\\}$$\n",
    "\n",
    "That is, it is the set of all two-tuples with the first element from set $A$ and the second element from set $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The number of **permutations** of $n$ objects is the number of orderings of those $n$ objects, and can be calculated as\n",
    "\n",
    "$$ n \\cdot (n-1) \\cdot (n-2) \\cdot \\ldots \\cdot 2 \\cdot 1 \\\\ = n! $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sampling with replacement and with ordering**\n",
    "\n",
    "Consider choosing $k$ values from a set of $n$ values. The result is a $k$-tuple: $(x_1, x_2, \\ldots, x_k)$, \n",
    "where $x_i \\in A, \\forall i=1,2,\\ldots, k$. \n",
    "\n",
    "Thus, this is a combined experiment with $|S_1|=|S_2|=\\ldots=|S_k|=|A|\\equiv n$.\\\\\n",
    "\n",
    "Therefore the number of distinct ordered $k$-tuple outcomes is $n^k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sampling without replacement and with ordering**\n",
    "    \n",
    "In general, the number of ways to choose $k$ items from $n$ items **without replacement** and **with ordering** is\n",
    "\n",
    "$$ n \\cdot (n-1) \\cdot \\ldots \\cdot (n-k+1) = \\frac{n!}{(n-k)!} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sampling without Replacement and without Ordering**\n",
    "    \n",
    "The number of ways to choose $k$ items from a set of $n$ items **without replacement** and **without ordering** is\n",
    "\n",
    "$$  \\frac{n!}{(n-k)!k!} $$\n",
    "\n",
    "The value of the equation can also be expressed as\n",
    "$$\\binom{n}{k} = C^{n}_{k} $$\n",
    "\n",
    "and is know as the **binomial coefficient**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sampling with Replacement and without Ordering**\n",
    "\n",
    "The number of ways to sample from a set $A=\\{a_1,a_2,\\cdots,a_n\\}$ $k$ times **with replacement** and **without ordering** is\n",
    "\n",
    "$$C^{n + k - 1}_{k} = \\binom{n + k - 1}{k} = \\frac{(n+k-1)!}{k!}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Conditional Probability\n",
    "\n",
    "The conditional probability of event $A$ given that event $B$ has occurred is:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A\\cap B)}{P(B)}$$\n",
    "\n",
    "assuming that $P(B)>0$. Equivalently we can write:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$P(A\\cap B) = P(B|A)P(A)$$\n",
    "\n",
    "this is called a **chain rule**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Example: intersection of 3 events: $P(A\\cap B\\cap C) = P(A|B\\cap C)P(B|C)P(C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Statistically Independence\n",
    "\n",
    "Events $A$ and $B$ are **statistically independent (s.i.)** if and only if\n",
    "\n",
    "$$P(A\\cap B) = P(A)P(B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* With this result, we say that $A$ is **statistically independent (s.i.)** of $B$ if \n",
    "$$P(A|B) = P(A)$$\n",
    "\n",
    "* Equivalently, we say that $B$ is **statistically independent (s.i.)** of $A$ if \n",
    "$$P(B|A) = P(B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Total Probability Theorem (or Law of Total Probability)\n",
    "\n",
    "Let $\\{A_i\\}$ be disjoint events (partitions) that form the sample space $\\Omega$, and assume that $P(A_i)>0$ for all $i=1,\\dots,n$. Then, for any event $B$, by the **Law of Total Probability** we have\n",
    "\n",
    "$$P(B) = \\sum_i P(B|A_i)P(A_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The Law of Total Probability is often used in problems where there is a **hidden state**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Example: Suppose that a magician has two coins (1 fair coin and 1 2-headed coin). Let $H_i$ denote the event that the outcome of flip $i$ is heads. Then:\n",
    "$$P(H_1) = P(H_1|F)P(F) + P(H_1|\\bar{F})P(\\bar{F}) = \\frac{1}{2}\\times\\frac{1}{2} + 1\\times\\frac{1}{2} = \\frac{3}{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayes' Rule\n",
    "\n",
    "Let $\\{A_i\\}$ be disjoint events (partitions) that form the sample space $\\Omega$, and assume that $P(A_i)>0$ for all $i$. Then, for any event $B$ such that $P(B)>0$, by the **Bayes' Rule** we have\n",
    "\n",
    "$$P(A_i|B) = \\frac{P(B|A_i)P(A_i)}{P(B)}$$\n",
    "\n",
    "where \n",
    "\n",
    "* $P(A_i|B)$ is called the **posterior**\n",
    "* $P(B|A_i)$ is called the **likelihood**\n",
    "* $P(A_i)$ is called the **prior**\n",
    "* $P(B)$ is called the **evidence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Using the Law of Total Probability:\n",
    "\n",
    "$$P(A_i|B) = \\frac{P(B|A_i)P(A_i)}{\\sum_i P(B|A_i)P(A_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Inference\n",
    "\n",
    "Bayes's Rule is often used for **inference**, that is, we observe an effect, and we wish to *infer* the cause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Maximum Likelihood**\n",
    "\n",
    "* Frequentist approach\n",
    "\n",
    "* Decision Rule:\n",
    "$$P(\\text{event}|A_0) \\underset{A_1}{\\overset{A_0}{\\gtrless}} P(\\text{event}|A_1)$$\n",
    "\n",
    "* Uses observational data (likelihood) only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Maximum A Posteriori**\n",
    "\n",
    "* Bayesian approach\n",
    "* Decision Rule:\n",
    "\n",
    "$$P(A_0|\\text{event}) \\underset{A_1}{\\overset{A_0}{\\gtrless}} P(A_1| \\text{event})$$\n",
    "\n",
    "* Makes use of posterior, which assumes a prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary Statistics & Resampling\n",
    "\n",
    "* A **population** is a group of people, objects, events, observations, etc. that is being studied.\n",
    "\n",
    "* Often we are trying to assess some qualities or properties of that population. We call these **parameters**.\n",
    "\n",
    "* A **sample** from a population is a subset of the population that can be used to draw inferences about the parameters of interest.\n",
    "\n",
    "* A **statistic** is a measurement of a quality or property on a sample that is used to assess a parameter of the whole population.\n",
    "    * Common statistics include: sample mean, sample variance, percentiles.\n",
    "\n",
    "* **Bootstrapping** is any test or metric that relies on **random sampling with replacement**. Bootstrapping allows assigning measures of accuracy to sample estimates.\n",
    "    * *The Bootstrap Idea*: the original sample approximates the population from which it was drawn. So resamples from this sample approximate what we would get if we took many samples from the population. The bootstrap distribution of a statistic, based on many resamples, approximates the sampling distribution of the statistic, based on many samples.\n",
    "\n",
    "* **Permutation** is any test or metric that relies on **all possible rearrangements of the observed data points**. \n",
    "    * When there are too many possible orderings, **Monte Carlo** sampling considered a small random sample of the possible replicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "There are broadly two types of hypothesis testing:\n",
    "\n",
    "1. Classical hypothesis testing, or *Frequentist* hypothesis test\n",
    "2. Bayesian hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Classical Hypothesis Testing\n",
    "\n",
    "A *statistical hypothesis* is a hypothesis that is testable on the basis of observing a process that is modeled via a set of random variables.\n",
    "For example: suppose that you toss a coin 10 times and observe Heads 10 times. Is the coin fair? Or $P(HH\\dots H|\\text{coin is fair})$?\n",
    "\n",
    "In **Classical (binary) Hypothesis Testing** we set up two hypothesis:\n",
    "\n",
    "$H_0$: (the *null hypothesis*) is that the observed effect is just caused by randomness in the sampling. It is not real in the underlying system or data. For the example above, our null hypothesis is that the coin is actually fair.\n",
    "\n",
    "$H_1$: (the *alternative hypothesis*) is that the observed effect is not just caused by random sampling. In this example, the coin is biased toward Heads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The next step of a hypothesis test generally involves setting up a simulation to compute the probability of the observed effect (in this case, flipping a coin 10 times and observing 10 Heads).\n",
    "\n",
    "* The probability of observing an effect of the same size under the null hypothesis is called the **$p$-value**.\n",
    "\n",
    "* In classical statistics/hypothesis testing, we say that an effect is **statistically significant** if the $p$-value is *smaller than* some small value $\\alpha$. \n",
    "    * $\\alpha$ is called the **significance level**.\n",
    "    * Typical values of $\\alpha$ are 0.05 or 0.01, but many argue for even smaller values now. \n",
    "    \n",
    "* The threshold to determine statistical significance,$\\alpha$, must always be determined before the experiment is conducted -- otherwise, there is too much temptation to adjust the threshold based on the observed $p$-value.\n",
    "\n",
    "In classical hypothesis testing, we do *not* test the alternative hypothesis directly, nor can we utilize side information that we may already have about the two hypotheses. In fact, when:\n",
    "* $p$-value$<\\alpha$, we say that the test is statistically significant and therefore we *reject* the null hypothesis.\n",
    "* $p$-value$\\geq \\alpha$, we say that the test is not statistically significant, we *fail to reject* the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Types of Error\n",
    "\n",
    "In binary hypothesis testing, there are two types of errors:\n",
    "\n",
    "1. **Type I Error**, False Alarm or False Positive: occurs if we accept a hypothesis when it is not true, $P_{fa}=P(\\text{false alarm}) = \\alpha$\n",
    "\n",
    "2. **Type II Error**, miss or False Negative: occurs if we reject a hypothesis when it is actually true, $P_m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "The **ROC curve** is a plot that illustrates the diagnostic ability of a binary hypothesis test as its significance threshold is varied.\n",
    "\n",
    "* the x-axis is **FPR (false positive rate)**\n",
    "$$\\text{FPR}=P_{fa}$$\n",
    "* the y-axis is **TPR (true positive rate)**\n",
    "$$\\text{TPR}=1-P_m$$\n",
    "\n",
    "The best ROC curve will look like a *step function* and the **area under the curve (AUC)** is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayesian Hypothesis Testing\n",
    "\n",
    "**Bayesian hypothesis testing**, similar to Bayesian inference and in contrast to frequentist hypothesis testing, is about comparing the prior knowledge about research hypothesis to posterior knowledge about the hypothesis rather than accepting or rejecting a very specific hypothesis based on the experimental data.\n",
    "\n",
    "For example, suppose that you toss a coin 10 times and observe Heads 10 times. Is the coin fair? If a magician had given you this coin, would it change this probability? \n",
    "\n",
    "* This *prior* knowledge can be used to compute the posterior probability using the Bayes' Rule:\n",
    "$$P(\\text{coin is fair}|HH\\dots H) = \\frac{P(HH\\dots H|\\text{coin is fair})P(\\text{coin is fair})}{P(HH\\dots H)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Bayesian hypothesis testing *test hypothesis* whereas Frequentist hypothesis testing assign *probability to hypothesis*.\n",
    "\n",
    "* For the set of a posterior probabilites, a Bayesian hypothesis testing typically computes a **confidence intervals** for which values the null hypothesis is acceptable.\n",
    "\n",
    "* Similarly, a significance value $\\alpha$ is defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Popular tests:\n",
    "\n",
    "* $Z$-Test\n",
    "* $T$-Test\n",
    "* $\\chi^2$-test (reads chi-squared)\n",
    "* McNemar's Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Goodness of Fit\n",
    "\n",
    "In some cases, we can test on whether a set of observations follows a standard distribution.\n",
    "\n",
    "* For **discrete distributions**, we can use the $\\chi^2$-test\n",
    "\n",
    "* For **continuous distributions**, we can use **probability plots** or Quantile-Quantile (Q-Q) plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Random Variables\n",
    "\n",
    "Given an experiment and the corresponding set of possible outcomes (the sample space), a **random variable** associates a particular *number* with each outcome. We refer to this number as the numerical value or simply the **value** of the RV. \n",
    "\n",
    "Mathematically, a random variable is a **real-valued function** of the experimental outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can have three types of random variables:\n",
    "\n",
    "* discrete\n",
    "* continuous\n",
    "* mixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Discrete Random Variable\n",
    "\n",
    "A random variable is called **discrete** if its range (the set of values that it can take) is either **finite** or **countably infinite**.\n",
    "\n",
    "* A discrete RV has an associate **probability mass function**, which gives the probability of each numerical value that the random variable can take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If $x$ is any real number, the **probability mass function** (or **PMF**) of the random variable $X$, denoted $p_X(x)$, is the probability of the event $\\{X=x\\}$ consisting of all outcomes that give rise to a value $X$ equal to $x$:\n",
    "\n",
    "$$p_X(x) = P(\\{X=x\\})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "where $\\sum_x p_X(x) = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The Bernoulli Random Variable\n",
    "\n",
    "An event $A\\in\\mathcal{\\Omega}$ is considered a \"success\".\n",
    "\n",
    "* A **Bernoulli RV** $X$ is defined by\n",
    "\n",
    "$$X = \\begin{cases}1, & s\\in A \\\\ 0,&s\\notin A \\end{cases}$$\n",
    "\n",
    "* We refer to $X$ as the **Bernoulli** RV **with probability of success $p$**:\n",
    "\n",
    "$$X \\sim \\text{Bernoulli}(p) $$\n",
    "\n",
    "* The PMF for a Bernoulli RV $X$ is defined by\n",
    "\n",
    "$$p_X(x) = P(X=x) = \\begin{cases}p,&x=1\\\\1-p,&x=0\\\\0,&x\\neq\\{0,1\\} \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The Binomial Random Variable\n",
    "\n",
    "A **Binomial random variable** can be defined as the sum of $n$ independent Bernoulli RVs.\n",
    "    \n",
    "* Let $X$ be the # of successes.\n",
    "    \n",
    "* We refer to $X$ as the **Binomial** RV **with parameters $n$ and $p$**:\n",
    "\n",
    "$$X \\sim \\text{Binomial}(n,p)$$\n",
    "\n",
    "* The PMF of $X$ is given by\n",
    "\n",
    "$$p_X(x) = P(X=k) = \\begin{cases} \\binom{n}{k} p^k (1-p)^{n-k}, & k=0,1,\\dots,n \\\\ 0, & \\text{otherwise (o.w.)} \\end{cases} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The Geometric Random Variable\n",
    "\n",
    "A **Geometric random variable** occurs when independent Bernoulli trials are conducted until the first success\n",
    "    \n",
    "* Let $X$ be the number of trials required. \n",
    "\n",
    "* We refer to $X$ as the **Geometric** RV with **probability $p$**:\n",
    "\n",
    "$$X \\sim \\text{Geometric}(p)$$\n",
    "\n",
    "* The PMF of $X$ is given by\n",
    "\n",
    "$$p_X(x) = P(X=x) = \\begin{cases}p(1-p)^{k-1}, & k=1,2,\\dots,n \\\\ 0, & \\text{o.w.}\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The Poisson Random Variable\n",
    "\n",
    "A **Poisson random variable** models events that occur randomly in space or time.\n",
    "\n",
    "* Let $\\lambda$ = the # of events/(unit of space or time) and consider observing some period of time or space of length $t$ and let $\\alpha= \\lambda t$.\n",
    "\n",
    "\n",
    "* Let $X$= the # events in time (or space) $t$. We refer to $X$ as the **Poisson** RV with $x$ event:\n",
    "\n",
    "$$X \\sim \\text{Poisson}(x)$$\n",
    "\n",
    "* The PMF of the Poisson random variable is\n",
    "$$ P_N(n) = \n",
    "\\begin{cases}\n",
    "\\frac{\\alpha^n}{n!} e^{-\\alpha}, & n=0,1,\\ldots \\\\\n",
    "0, & \\mbox{o.w.}\n",
    "\\end{cases} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Continuous Random Variable\n",
    "\n",
    "A random variable $X$ is called **continuous** if its range (the set of values that it can take) is **uncountably infinite** and its probability law can be described in terms of a *nonnegative* function $f_X$ called **probability density function** (or **PDF**) of $X$, which satisfies\n",
    "\n",
    "$$P(X\\in B) = \\int_B f_X(x) dx,$$\n",
    "\n",
    "for every subset $B$ of the real line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Continuous RVs do not have probability at any discrete points, that is,\n",
    "\n",
    "$$P(X = x) = 0, \\forall x\\in \\mathbb{R}$$\n",
    "\n",
    "* This only means the event $X=x$ is *extremely unlikely* but not impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**PDF Properties**\n",
    "\n",
    "1. $f_X(x)\\geq 0$ for all $x$.\n",
    "\n",
    "2. $\\int_\\limits{-\\infty}^{\\infty} f_X(x)dx = 1$.\n",
    "\n",
    "3. If $\\delta$ is small, then $P([x,x+\\delta]) \\approx f_X(x)\\cdot\\delta$.\n",
    "\n",
    "4. For any subset $B$ of the real line,\n",
    "\n",
    "$$P(X\\in B) = \\int_B f_X(x) dx.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cumulative Distribution Functions\n",
    "\n",
    "If $(\\Omega,\\mathcal{F},P)$ is a probability space with $X$ a real discrete RV on $\\Omega$, the **Cumulative Distribution Function (CDF)** is denoted as $F_X(x)$ and provides the probability $P(X\\leq x)$. In particular, for every $x$ we have\n",
    "\n",
    "$$F_X(x) = P(X\\leq x) = \\begin{cases} \\sum_\\limits{k\\leq x} p_X(k) & X: \\text{ discrete} \\\\ \\int_\\limits{-\\infty}^x f_X(t)dt & X:\\text{ continuous}  \\end{cases}$$ \n",
    "\n",
    "Loosely speaking, the CDF $F_X(x)$ \"accumulates\" probability \"up to\" the value $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The CDF $F_X(x)$ is a probability measure therefore it inherits all the properties of a probability measure.\n",
    "\n",
    "* If $X$ is continuous, the PDF and CDF can be obtained from each other by integration or differentiation:\n",
    "\n",
    "$$F_X(x) = \\int_\\limits{-\\infty}^x f_X(t) dt,$$\n",
    "$$f_X(x) = \\frac{dF_X}{dx}(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Survival Function\n",
    "\n",
    "If $(\\Omega,\\mathcal{F},P)$ is a probability space with $X$ a real discrete RV on $\\Omega$, the **Survival Function (SF)** is denoted as $S_X(x)$ and provides the probability $P(X > x)$. In particular, for every $x$ we have\n",
    "\n",
    "$$S_X(x) = P(X > x) = 1 - P(X \\leq x) = 1 -F_X(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The Uniform Random Variable\n",
    "\n",
    "A random variable $X$ that takes values in an interval $[a,b]$, and all subintervals of the same length are equally likely, is called a **uniform** or **uniformly distributed** random variable. Its PDF has the form:\n",
    "\n",
    "$$f_X(x) = \\begin{cases} \\frac{1}{b-a} & \\text{if } a\\leq x\\leq b,\\\\ 0 & \\text{otherwise}\\end{cases}$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**The Exponential Random Variable**\n",
    "\n",
    "An **exponential** random variable represents the time between events that occur continuously and independently at a constant average rate $\\lambda$. Its PDF has the form:\n",
    "\n",
    "$$f_X(x) = \\begin{cases} \\lambda e^{-\\lambda x} & x\\geq 0\\\\ 0 & x<0 \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* An exponential random variable can be obtainable as a limit of Geometric random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**The Gaussian Random Variable**\n",
    "\n",
    "A continuous random variable $X$ is said to be **Gaussian** if it has a PDF form\n",
    "\n",
    "$$f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-(x-\\mu)^2/2\\sigma^2}$$\n",
    "\n",
    "with mean $\\mu$ and variance $\\sigma^2\\geq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A random variable is called **Normal** if it is a **Gaussian** random variable with mean $\\mu=0$ and variance $\\sigma^2=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Limit Theorems\n",
    "\n",
    "* The **Weak Law of Large Numbers**: asserts that the sample mean of a large number of independent identically distributed random variables is very close to the true mean, with high probability.\n",
    "\n",
    "* The **Central Limit Theorem**: asserts that the sum of a large number of independent and identically distributed (not necessarily Normal) random variables has an approximately Normal CDF, regardless of the CDF of the individual random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expected Value\n",
    "\n",
    "If $x_i$ are samples drawn from a random variable $X$, then the **expected value** or **mean** of the random variable $X$ is\n",
    "\n",
    "$$\\mu_X = E[X] = \\sum_\\limits{i} x_i p_X(x_i) \\text{, if }X\\text{ is discrete}$$\n",
    "\n",
    "$$\\mu_X = E[X] = \\int_\\limits{-\\infty}^{\\infty} x f_X(x) dx \\text{, if }X\\text{ is continuous}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Moments\n",
    "\n",
    "The **moments** of a random variable (or of its distribution) are *expected values of powers* or related functions of the random variable.\n",
    "\n",
    "The $r$-th moment of RV $X$ is $E[X^r]$.\n",
    "\n",
    "* In particular, the first moment is the *mean*, $\\mu_X = E[X]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Central Moments\n",
    "\n",
    "The **central moments** of a random variable (or of its distribution) are *expected values of mean-centered powers* or related functions of the random variable.\n",
    "\n",
    "The $r$-th central moment of RV $X$ is $E[(X - \\mu_X)^r]$, in general, $E[(X - E[X])^r]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* In mathematics, a *moment* is a specific quantitative measure of the shape of a function. The most important ones are:\n",
    "\n",
    "    1. The **mean**, or the first moment of the random variable $X$: $E[X]$. It measures the average value of the its PDF.\n",
    "    2. The **variance**, or the second central moment of the random variable $X$: $E[(X-E[X])^2]$. It provides a measure of how much the PDF spreads away from the mean.\n",
    "    3. The **skewness**, or the third central moment of the random variable $X$: $E[(X-E[X])^3]$. It measures the amount of asymmetry of its PDF with respect to the mean value. For example, the skewness of a Normal distribution is 0.\n",
    "    4. The **kurtosis**, or the fourth central moment of the random variable $X$: $E[(X-E[X])^4]$. It's a measure of the tailedness of its PDF. For example, the Normal distribution has a kurtosis of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Variance\n",
    "\n",
    "The variance of a random variable $X$ is computed as the second central moment of its PDF:\n",
    "\n",
    "\\begin{align} Var[X] = \\sigma_X^2 &= E[(X-E[X])^2]\\\\\n",
    "&= E[X^2] - \\left(E[X]\\right)^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Properties of Variance:**\n",
    "\n",
    "Let $X$ be a random variable and $b$ and $c$ constant values.\n",
    "\n",
    "1. $Var[X] = E[X^2] - (E[X])^2 \\geq 0$\n",
    "\n",
    "2. $Var[c] = 0$\n",
    "\n",
    "3. $Var[X - c] = E[X^2] - (E[X])^2$\n",
    "\n",
    "4. $Var[cX] = c^2 Var[X]$\n",
    "\n",
    "5. $Var[cX + b] = c^2 Var[X]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Covariance\n",
    "\n",
    "The **covariance** of two random variables $X$ and $Y$, denoted by $\\text{cov}(X,Y)$, is defined by\n",
    "\n",
    "$$\\text{cov}(X,Y) = E\\bigl[\\left(X-E\\left[X\\right]\\right) \\left(Y-E\\left[Y\\right]\\right)\\bigr]$$\n",
    "\n",
    "* The *unbiased sample* covariance is given by: \n",
    "$$\\frac{1}{n-1} \\sum_{i=1}^{n} \\left(x_i - \\overline{x}\\right)\\left(y_i - \\overline{y}\\right)$$\n",
    "\n",
    "where $\\overline{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$ and $\\overline{y}= \\frac{1}{n} \\sum_{i=1}^n y_i$ are the sample means of the RVs $X$ and $Y$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The covariance matrix of two random variables $X$ and $Y$ is a $2\\times 2$ matrix:\n",
    "\n",
    "\\begin{align}\\Sigma = \\text{cov}(X,Y) &= \\left[\\begin{array}{cc}\\text{cov}(X,X) & \\text{cov}(X,Y) \\\\ \\text{cov}(Y,X) & \\text{cov}(Y,Y)   \\end{array}\\right] \\\\\n",
    "& = \\left[\\begin{array}{cc}\\text{var}(X) & \\text{cov}(X,Y) \\\\ \\text{cov}(X,Y) & \\text{var}(Y)   \\end{array}\\right]\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Pearson's Correlation Coefficient\n",
    "\n",
    "For random variables $X$ and $Y$, thwe **Pearson's correlation coefficient** (or simply the **correlation coefficient**) is\n",
    "\n",
    "$$ r = \\frac{\\operatorname{cov}(X,Y)}{\\sqrt{\\text{var}(X)}\\sqrt{\\text{var}(Y)}} = \\frac{\\text{cov}(X,Y)}{\\sigma_X \\sigma_Y}$$\n",
    "\n",
    "where $\\operatorname{cov}(X,Y)$ is the covariance and $\\sigma_X$ and $\\sigma_Y$ are the square-roots of the corresponding variances.\n",
    "\n",
    "* **Correlation is not causation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Coefficient of Determination\n",
    "\n",
    "The **coefficient of determination**, denoted $R^2$ or $r^2$ and pronounced \"R squared\", is the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
    "\n",
    "$$r^2 = 1 - \\frac{\\text{Explained Variation}}{\\text{Total Variation}}$$\n",
    "\n",
    "$$ 0 \\leq r^2 \\leq 1$$\n",
    "\n",
    "* $r^2$ is the square of the correlation coefficient $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Jointly Gaussian Random Variables\n",
    "\n",
    "Two **Gaussian** random variables $X$ and $Y$ are said to be *jointly Gaussian* if their joint density function (or multivariate Gaussian distribution) can be written as:\n",
    "\n",
    "$$f_{XY}(x,y) = \\frac{1}{(2\\pi)^{d/2} |\\Sigma|^{1/2}}\\exp\\left(-\\frac{1}{2}(\\mathbf{x}-\\mathbf{\\mu})^T\\Sigma^{-1}(\\mathbf{x}-\\mathbf{\\mu})\\right) $$\n",
    "\n",
    "where $d=2$, $\\mathbf{x}=[x,y]^T$, $\\mu=[\\mu_x,\\mu_y]^T$ and $\\Sigma$ is the **covariance** matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Two **Gaussian** random variables $X$ and $Y$ that each have mean 0 and variance 1 are said to be *jointly Gaussian* if their density function can be written as\n",
    "\n",
    "$$f_{X,Y}(x,y) = \\frac{1}{(2\\pi)^{d/2}\\sqrt{1-r^2}}\\exp\\left(-\\frac{(x^2-2rxy + y^2)}{2(1-r)^2}\\right) $$\n",
    "\n",
    "where $|r|<1$ is the correlation coefficient for $X$ and $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Further Review\n",
    "\n",
    "If you are interested in reviewing these topics further, I recommend: \n",
    "\n",
    "* \"Introduction to Probability\" book by Bertsekas and Tsitsiklis, [available online](http://faculty.pucit.edu.pk/faisal/ma249/book.pdf)\n",
    "\n",
    "* \"Seeing Theory\", an interactive tool for review of probability and statistics, [link](https://seeing-theory.brown.edu/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
